{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":51753,"databundleVersionId":5692552,"sourceType":"competition"},{"sourceId":5888553,"sourceType":"datasetVersion","datasetId":3383521}],"dockerImageVersionId":30474,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <center>⭐ Config ⭐</center>","metadata":{}},{"cell_type":"code","source":"!pip install -q -U segmentation-models-pytorch albumentations > /dev/null\nimport segmentation_models_pytorch as smp","metadata":{"execution":{"iopub.status.busy":"2023-06-13T13:58:07.541372Z","iopub.execute_input":"2023-06-13T13:58:07.541970Z","iopub.status.idle":"2023-06-13T13:58:22.915746Z","shell.execute_reply.started":"2023-06-13T13:58:07.541919Z","shell.execute_reply":"2023-06-13T13:58:22.914356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport albumentations as A\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom torch.cuda.amp import GradScaler, autocast\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nimport random\nimport sys\nimport cv2\n\nfrom tqdm.notebook import tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-13T13:58:22.918859Z","iopub.execute_input":"2023-06-13T13:58:22.919403Z","iopub.status.idle":"2023-06-13T13:58:25.361235Z","shell.execute_reply.started":"2023-06-13T13:58:22.919353Z","shell.execute_reply":"2023-06-13T13:58:25.360035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data_path = '/kaggle/input/contrail-data-torch/train'\ntrain_label_path = '/kaggle/input/contrail-data-torch/train_labels'\n\nval_data_path = '/kaggle/input/contrail-data-torch/val'\nval_label_path = '/kaggle/input/contrail-data-torch/val_labels'\n\nDEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'","metadata":{"execution":{"iopub.status.busy":"2023-06-13T13:58:25.362453Z","iopub.execute_input":"2023-06-13T13:58:25.362841Z","iopub.status.idle":"2023-06-13T13:58:25.372064Z","shell.execute_reply.started":"2023-06-13T13:58:25.362793Z","shell.execute_reply":"2023-06-13T13:58:25.370705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def set_seed(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\nset_seed()","metadata":{"execution":{"iopub.status.busy":"2023-06-13T13:58:58.987704Z","iopub.execute_input":"2023-06-13T13:58:58.988194Z","iopub.status.idle":"2023-06-13T13:58:58.996799Z","shell.execute_reply.started":"2023-06-13T13:58:58.988158Z","shell.execute_reply":"2023-06-13T13:58:58.995974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def visualize(**images):\n    plt.figure(figsize=(18, 6))\n    \n    ax = plt.subplot(1, 3, 1)\n    ax.imshow(images['image'])\n    ax.set_title('False color image')\n    \n    ax = plt.subplot(1, 3, 2)\n    ax.imshow(images['mask'])\n    ax.set_title('Ground truth contrail mask')\n        \n    ax = plt.subplot(1, 3, 3)\n    ax.imshow(images['image'])\n    ax.imshow(images['mask'], cmap='Reds', alpha=.4, interpolation='none')\n    \n    plt.show();\n    \ndef one_hot_encode(label, label_values):\n    semantic_map = []\n    \n    for color in label_values:\n        equality = np.equal(label, color)\n        class_map = np.all(equality, axis=-1)\n        semantic_map.append(class_map)\n        \n    semantic_map = np.stack(semantic_map, axis=-1)\n    \n    return semantic_map\n\ndef reverse_one_hot(image):\n    x = np.argmax(image, axis=-1)\n    return x\n\ndef color_codr_segmentation(image, label_values):\n    color_codes = np.array(label_values)\n    x = color_codes[image.astype(int)]\n    \n    return x","metadata":{"execution":{"iopub.status.busy":"2023-06-13T13:59:01.909815Z","iopub.execute_input":"2023-06-13T13:59:01.910270Z","iopub.status.idle":"2023-06-13T13:59:01.923093Z","shell.execute_reply.started":"2023-06-13T13:59:01.910238Z","shell.execute_reply":"2023-06-13T13:59:01.921533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <center>⭐ DataAugmentation & DataSet ⭐</center>","metadata":{}},{"cell_type":"code","source":"# A_transform = [\n#     A.OneOf([\n#         A.RandomBrightnessContrast(brightness_limit=(-0.3, 0.3), contrast_limit=(-0.3, 0.3), p=1),# 밝기와 대비 변경\n#         A.RandomBrightnessContrast(brightness_limit=(-0.8, 0.8), contrast_limit=0, p=1), # 밝기만 변경\n#         A.RandomBrightnessContrast(brightness_limit=0, contrast_limit=(-0.8, 0.8), p=1), # 대비만 변경\n        \n#         # 색상 채도 명도 변경. default(hue_shift_limit=(-20, 20), sat_shift_limit=(-30, 30), val_shift_limit=(-20, 20))\n#         A.HueSaturationValue(p=1),\n#         # RGB 값을 각각 범위내 임의로 변경 default(r_shift_limit=(-20, 20), g_shift_limit=(-20, 20), b_shift_limit=(-20, 20))\n#         A.RGBShift(p=1),\n#         # RGB Channel을 랜덤하게 섞음\n#         A.ChannelShuffle(p=1),\n        \n#         # 가우시안 노이즈 분포를 가지는 노이즈를 추가\n#         A.GaussNoise(p=1, var_limit=(100, 200)),\n#         # 정사각형 노이즈 추가\n#         A.Cutout(p=1, num_holes=8, max_h_size=24, max_w_size=24),\n        \n#         # 히스토그램 균일화 기법인 CLAHE를 이용하여 보다 선명한 이미지 발생\n#         A.CLAHE(p=1),\n#         # blur_limit가 클수록 더 흐림\n#         A.Blur(p=1, blur_limit=(50, 60)),\n#     ])\n# ]","metadata":{"execution":{"iopub.status.busy":"2023-05-31T10:12:40.275824Z","iopub.execute_input":"2023-05-31T10:12:40.276365Z","iopub.status.idle":"2023-05-31T10:12:40.287287Z","shell.execute_reply.started":"2023-05-31T10:12:40.276329Z","shell.execute_reply":"2023-05-31T10:12:40.286236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_training_augmentation():\n    train_transform = A.Compose([\n        # A.Resize(384, 384, interpolation=cv2.INTER_CUBIC),\n        # A.ChannelShuffle(p=0.5),\n#         A.HueSaturationValue(p=0.5, hue_shift_limit=(0, 20), sat_shift_limit=(0, 30), val_shift_limit=(0, 20)),\n#         A.RandomBrightnessContrast(brightness_limit=(-0.3, 0.3), contrast_limit=(-0.3, 0.3), p=0.5),\n#         A.GaussNoise(p=0.5, var_limit=(0, 0.001)),\n#         A.OneOf([\n#             A.Sharpen(p=0.5),\n#             A.CLAHE(p=0.5),\n#             A.Emboss(p=1),\n#         ]),\n        A.OneOf(\n            [\n                A.HorizontalFlip(p=1),\n                A.VerticalFlip(p=1),\n                A.RandomRotate90(p=1),\n            ],p=0.5),\n  \n        A.PadIfNeeded(min_height=256, min_width=256, always_apply=True, border_mode=0),\n        A.Normalize()\n    ])\n    \n    return train_transform\n\ndef get_val_augmentation():   \n    test_transform = [\n        A.PadIfNeeded(min_height=256, min_width=256, always_apply=True, border_mode=0),\n        # A.Resize(384, 384, interpolation=cv2.INTER_CUBIC)\n        A.Normalize()\n    ]\n    return A.Compose(test_transform)\n\n\ndef to_tensor(x, **kwargs):\n    return x.transpose(2, 0, 1).astype('float32')\n\ndef to_tensor(x, **kwargs):\n    return x.transpose(2, 0, 1)\n\ndef get_preprocessing(preprocessing_fn=None):\n    _transform = []\n    if preprocessing_fn:\n        _transform.append(A.Lambda(image=preprocessing_fn))\n    _transform.append(A.Lambda(image=to_tensor, mask=to_tensor))\n        \n    return A.Compose(_transform)","metadata":{"execution":{"iopub.status.busy":"2023-06-13T14:00:31.293339Z","iopub.execute_input":"2023-06-13T14:00:31.293749Z","iopub.status.idle":"2023-06-13T14:00:31.305651Z","shell.execute_reply.started":"2023-06-13T14:00:31.293719Z","shell.execute_reply":"2023-06-13T14:00:31.304462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ContrailDataset(Dataset):\n    def __init__(self, images_dir, masks_dir, augmentation=None, preprocessing=None):\n        super().__init__()\n        self.image_path = [os.path.join(images_dir, image_id) for image_id in sorted(os.listdir(images_dir))]\n        self.mask_path = [os.path.join(masks_dir, image_id) for image_id in sorted(os.listdir(masks_dir))]\n        \n        self.augmentation = augmentation\n        self.preprocessing = preprocessing\n        \n    def __len__(self):\n        return len(self.image_path)\n        \n    def __getitem__(self, idx):\n        image = np.load(self.image_path[idx])\n        mask = np.load(self.mask_path[idx])\n        \n        if self.augmentation:\n            sample = self.augmentation(image=image, mask=mask)\n            image, mask = sample['image'], sample['mask']\n            \n        if self.preprocessing:\n            image = np.transpose(image, (2, 0, 1))\n            mask = np.transpose(mask, (2, 0, 1))\n#             sample = self.preprocessing(image=image, mask=mask)\n#             image, mask = sample['image'], sample['mask']\n            \n        image = image.astype(np.float32)\n        mask = mask.astype(np.float32)\n            \n        return image, mask","metadata":{"execution":{"iopub.status.busy":"2023-06-13T13:59:05.039978Z","iopub.execute_input":"2023-06-13T13:59:05.040913Z","iopub.status.idle":"2023-06-13T13:59:05.052851Z","shell.execute_reply.started":"2023-06-13T13:59:05.040873Z","shell.execute_reply":"2023-06-13T13:59:05.051439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(3):\n    prac_train = ContrailDataset(val_data_path, val_label_path)\n    random_idx = random.randint(0, len(prac_train) - 1)\n    # image, mask = prac_train[random_idx]\n    image, mask = prac_train[i]\n\n    visualize(\n        image=image,\n        mask=mask\n    )\n\n    train_ds = ContrailDataset(val_data_path, val_label_path, get_training_augmentation())\n    # image, mask = train_ds[random_idx]\n    image, mask = train_ds[i]\n\n    visualize(\n        image=image,\n        mask=mask\n    )","metadata":{"execution":{"iopub.status.busy":"2023-06-12T00:26:08.590955Z","iopub.execute_input":"2023-06-12T00:26:08.591357Z","iopub.status.idle":"2023-06-12T00:26:14.950064Z","shell.execute_reply.started":"2023-06-12T00:26:08.591321Z","shell.execute_reply":"2023-06-12T00:26:14.948790Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <center>⭐ Model Config & Model ⭐</center>","metadata":{}},{"cell_type":"code","source":"class Meter(object):\n    def reset(self):\n        pass\n\n    def add(self, value):\n        pass\n\n    def value(self):\n        pass\n\nclass AverageValueMeter(Meter):\n    def __init__(self):\n        super(AverageValueMeter, self).__init__()\n        self.reset()\n        self.val = 0\n\n    def add(self, value, n=1):\n        self.val = value\n        self.sum += value\n        self.var += value * value\n        self.n += n\n\n        if self.n == 0:\n            self.mean, self.std = np.nan, np.nan\n        elif self.n == 1:\n            self.mean = 0.0 + self.sum  # This is to force a copy in torch/numpy\n            self.std = np.inf\n            self.mean_old = self.mean\n            self.m_s = 0.0\n        else:\n            self.mean = self.mean_old + (value - n * self.mean_old) / float(self.n)\n            self.m_s += (value - self.mean_old) * (value - self.mean)\n            self.mean_old = self.mean\n            self.std = np.sqrt(self.m_s / (self.n - 1.0))\n\n    def value(self):\n        return self.mean, self.std\n\n    def reset(self):\n        self.n = 0\n        self.sum = 0.0\n        self.var = 0.0\n        self.val = 0.0\n        self.mean = np.nan\n        self.mean_old = 0.0\n        self.m_s = 0.0\n        self.std = np.nan","metadata":{"execution":{"iopub.status.busy":"2023-06-12T00:26:14.952498Z","iopub.execute_input":"2023-06-12T00:26:14.952982Z","iopub.status.idle":"2023-06-12T00:26:14.969876Z","shell.execute_reply.started":"2023-06-12T00:26:14.952941Z","shell.execute_reply":"2023-06-12T00:26:14.968354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Epoch:\n    def __init__(self, model, loss, metrics, stage_name, device=\"cpu\", verbose=True):\n        self.model = model\n        self.loss = loss\n        self.metrics = metrics\n        self.stage_name = stage_name\n        self.verbose = verbose\n        self.device = device\n\n        self._to_device()\n\n    def _to_device(self):\n        self.model.to(self.device)\n        self.loss.to(self.device)\n        for metric in self.metrics:\n            metric.to(self.device)\n\n    def _format_logs(self, logs):\n        str_logs = [\"{} - {:.4}\".format(k, v) for k, v in logs.items()]\n        s = \", \".join(str_logs)\n        return s\n\n    def batch_update(self, x, y):\n        raise NotImplementedError\n\n    def on_epoch_start(self):\n        pass\n\n    def run(self, dataloader):\n        self.on_epoch_start()\n\n        logs = {}\n        loss_meter = AverageValueMeter()\n        metrics_meters = {metric.__name__: AverageValueMeter() for metric in self.metrics}\n\n        with tqdm(\n            dataloader,\n            desc=self.stage_name,\n            file=sys.stdout,\n            disable=not (self.verbose),\n        ) as iterator:\n            for x, y in iterator:\n                x, y = x.to(self.device), y.to(self.device)\n                loss, y_pred = self.batch_update(x, y)\n\n                # update loss logs\n                loss_value = loss.cpu().detach().numpy()\n                loss_meter.add(loss_value)\n                loss_logs = {self.loss.__name__: loss_meter.mean}\n                logs.update(loss_logs)\n\n                # update metrics logs\n                for metric_fn in self.metrics:\n                    metric_value = metric_fn(y_pred, y).cpu().detach().numpy()\n                    metrics_meters[metric_fn.__name__].add(metric_value)\n                metrics_logs = {k: v.mean for k, v in metrics_meters.items()}\n                logs.update(metrics_logs)\n\n                if self.verbose:\n                    s = self._format_logs(logs)\n                    iterator.set_postfix_str(s)\n        return logs\n\nclass TrainEpoch(Epoch):\n    def __init__(self, model, loss, metrics, optimizer, scheduler, device=\"cpu\", verbose=True):\n        super().__init__(\n            model=model,\n            loss=loss,\n            metrics=metrics,\n            stage_name=\"train\",\n            device=device,\n            verbose=verbose,\n        )\n        self.scaler = GradScaler()\n        self.optimizer = optimizer\n        self.scheduler = scheduler\n\n    def on_epoch_start(self):\n        self.model.train()\n\n    def batch_update(self, x, y):\n        self.optimizer.zero_grad()\n        with autocast(): # amp\n            prediction = self.model.forward(x)\n            loss = self.loss(prediction, y)\n            bce_loss = torch.nn.functional.binary_cross_entropy_with_logits(prediction, y)\n            loss = loss + bce_loss\n        self.scaler.scale(loss).backward()\n        self.scaler.step(self.optimizer)\n        self.scaler.update()\n        self.scheduler.step()\n        \n        return loss, prediction\n\nclass ValidEpoch(Epoch):\n    def __init__(self, model, loss, metrics, device=\"cpu\", verbose=True):\n        super().__init__(\n            model=model,\n            loss=loss,\n            metrics=metrics,\n            stage_name=\"valid\",\n            device=device,\n            verbose=verbose,\n        )\n\n    def on_epoch_start(self):\n        self.model.eval()\n\n    def batch_update(self, x, y):\n        with torch.no_grad():\n            prediction = self.model.forward(x)\n            loss = self.loss(prediction, y)\n        return loss, prediction","metadata":{"execution":{"iopub.status.busy":"2023-06-12T00:52:34.037838Z","iopub.execute_input":"2023-06-12T00:52:34.038237Z","iopub.status.idle":"2023-06-12T00:52:34.064485Z","shell.execute_reply.started":"2023-06-12T00:52:34.038205Z","shell.execute_reply":"2023-06-12T00:52:34.063647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import segmentation_models_pytorch.utils.metrics\nimport segmentation_models_pytorch.utils\n\n# ENCODER = 'resnet50'\nENCODER = 'efficientnet-b1'\nENCODER_WEIGHTS = 'imagenet'\nCLASSES = ['Contrail']\nACTIVATION = 'sigmoid'\n\nmodel = smp.Unet(\n    encoder_name=ENCODER,\n    encoder_weights=ENCODER_WEIGHTS,\n    classes = len(CLASSES),\n    activation = ACTIVATION,\n)\n\n# preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)\n\nbatch_size = 64\nsteps_per_epoch = int(len(os.listdir(train_data_path)) / batch_size) + 1\nTRAINING = True\nEpochs = 20\nloss = smp.utils.losses.DiceLoss()\nmetrics = [smp.utils.metrics.IoU(threshold=0.5)]\noptim = torch.optim.Adam([dict(params=model.parameters(), lr=0.0001)])\n# optim = torch.optim.AdamW(model.parameters(), lr=0.003, weight_decay=0.0)\nscheduler = torch.optim.lr_scheduler.OneCycleLR(optim, max_lr=0.01, epochs=Epochs, steps_per_epoch=steps_per_epoch)\n# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optim, T_max=500, eta_min=1e-06, last_epoch=-1)\n\n# model = torch.load('/kaggle/input/contrail-best-model-saved/EffNet_b0_BCE_0.01_Add_Zero.pth', map_location=DEVICE)","metadata":{"execution":{"iopub.status.busy":"2023-06-13T13:59:15.816019Z","iopub.execute_input":"2023-06-13T13:59:15.816458Z","iopub.status.idle":"2023-06-13T13:59:16.998201Z","shell.execute_reply.started":"2023-06-13T13:59:15.816425Z","shell.execute_reply":"2023-06-13T13:59:16.996960Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds = ContrailDataset(train_data_path, train_label_path, get_training_augmentation(), preprocessing=True)\nval_ds = ContrailDataset(val_data_path, val_label_path, get_val_augmentation(), preprocessing=True)\n\ntrain_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=4)\nval_dl = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=4)","metadata":{"execution":{"iopub.status.busy":"2023-06-13T14:00:40.574888Z","iopub.execute_input":"2023-06-13T14:00:40.575352Z","iopub.status.idle":"2023-06-13T14:00:40.720524Z","shell.execute_reply.started":"2023-06-13T14:00:40.575319Z","shell.execute_reply":"2023-06-13T14:00:40.719424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_epoch = TrainEpoch(\n    model,\n    loss=loss,\n    metrics=metrics,\n    optimizer=optim,\n    scheduler = scheduler,\n    device=DEVICE,\n    verbose=True\n)\n\nval_epoch = ValidEpoch(\n    model,\n    loss=loss,\n    metrics=metrics,\n    device=DEVICE,\n    verbose=True\n)","metadata":{"execution":{"iopub.status.busy":"2023-06-12T00:52:42.932670Z","iopub.execute_input":"2023-06-12T00:52:42.933188Z","iopub.status.idle":"2023-06-12T00:52:42.961761Z","shell.execute_reply.started":"2023-06-12T00:52:42.933150Z","shell.execute_reply":"2023-06-12T00:52:42.959013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <center>⭐ Train & Val ⭐</center>","metadata":{}},{"cell_type":"code","source":"if TRAINING:\n    \n    best_iou_score = 0.0\n    train_logs_list, val_logs_list = [], []\n    \n    for i in tqdm(range(0, Epochs)):\n        print('\\nEpoch: {}'.format(i))\n        train_logs = train_epoch.run(train_dl)\n        val_logs = val_epoch.run(val_dl)\n        print(train_logs)\n        print(val_logs)\n        train_logs_list.append(train_logs)\n        val_logs_list.append(val_logs)\n        \n        if best_iou_score < val_logs['iou_score']:\n            best_iou_score = val_logs['iou_score']\n            torch.save(model, './best_model.pth')\n            print('Model Saved!')","metadata":{"execution":{"iopub.status.busy":"2023-06-12T00:52:44.793595Z","iopub.execute_input":"2023-06-12T00:52:44.794037Z","iopub.status.idle":"2023-06-12T00:53:04.752652Z","shell.execute_reply.started":"2023-06-12T00:52:44.794003Z","shell.execute_reply":"2023-06-12T00:53:04.750495Z"},"trusted":true},"execution_count":null,"outputs":[]}]}