{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":51753,"databundleVersionId":5692552,"sourceType":"competition"},{"sourceId":5764912,"sourceType":"datasetVersion","datasetId":3313529},{"sourceId":5944013,"sourceType":"datasetVersion","datasetId":3399834,"isSourceIdPinned":false}],"dockerImageVersionId":30498,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install /kaggle/input/segmentation-whl/timm-0.6.12-py3-none-any.whl\n!pip install /kaggle/input/segmentation-whl/efficientnet_pytorch-0.7.1-py3-none-any.whl\n!pip install /kaggle/input/segmentation-whl/pretrainedmodels-0.7.4-py3-none-any.whl\n!pip install /kaggle/input/segmentation-whl/segmentation_models_pytorch-0.3.2-py3-none-any.whl\n# !pip install -q -U segmentation-models-pytorch albumentations > /dev/null\nimport segmentation_models_pytorch as smp","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-15T06:08:56.627949Z","iopub.execute_input":"2023-06-15T06:08:56.628346Z","iopub.status.idle":"2023-06-15T06:09:45.580353Z","shell.execute_reply.started":"2023-06-15T06:08:56.628319Z","shell.execute_reply":"2023-06-15T06:09:45.579459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport albumentations as A\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nimport random\nimport pathlib\nimport cv2\n\nfrom pathlib import Path\nfrom albumentations import *\n\nfrom tqdm.notebook import tqdm","metadata":{"execution":{"iopub.status.busy":"2023-06-15T06:09:45.581963Z","iopub.execute_input":"2023-06-15T06:09:45.582694Z","iopub.status.idle":"2023-06-15T06:09:47.146440Z","shell.execute_reply.started":"2023-06-15T06:09:45.582665Z","shell.execute_reply":"2023-06-15T06:09:47.145547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data_path = '/kaggle/input/google-research-identify-contrails-reduce-global-warming/test'\n\nDEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'","metadata":{"execution":{"iopub.status.busy":"2023-06-15T06:10:45.424019Z","iopub.execute_input":"2023-06-15T06:10:45.424440Z","iopub.status.idle":"2023-06-15T06:10:45.429591Z","shell.execute_reply.started":"2023-06-15T06:10:45.424409Z","shell.execute_reply":"2023-06-15T06:10:45.428342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_training_augmentation():\n    train_transform = A.Compose([\n        A.Resize(384, 384, interpolation=cv2.INTER_CUBIC),\n#         A.HueSaturationValue(p=0.5),\n#         A.RandomBrightnessContrast(brightness_limit=(-0.3, 0.3), contrast_limit=(-0.3, 0.3), p=0.5),\n#         A.ChannelShuffle(p=1),\n        A.OneOf(\n            [\n                A.HorizontalFlip(p=1),\n                A.VerticalFlip(p=1),\n                A.RandomRotate90(p=1),\n            ],p=0.5,),\n        ])\n    \n    return train_transform\n\ndef get_val_augmentation():   \n    test_transform = [\n        A.PadIfNeeded(min_height=256, min_width=256, always_apply=True, border_mode=0),\n        A.Resize(384, 384, interpolation=cv2.INTER_CUBIC),\n    ]\n    return A.Compose(test_transform)\n\n\ndef to_tensor(x, **kwargs):\n    return x.transpose(2, 0, 1).astype('float32')\n\ndef to_tensor(x, **kwargs):\n    return x.transpose(2, 0, 1)\n\ndef get_preprocessing(preprocessing_fn=None):\n    _transform = []\n    if preprocessing_fn:\n        _transform.append(A.Lambda(image=preprocessing_fn))\n    _transform.append(A.Lambda(image=to_tensor, mask=to_tensor))\n        \n    return A.Compose(_transform)","metadata":{"execution":{"iopub.status.busy":"2023-06-15T06:10:47.144452Z","iopub.execute_input":"2023-06-15T06:10:47.145413Z","iopub.status.idle":"2023-06-15T06:10:47.153359Z","shell.execute_reply.started":"2023-06-15T06:10:47.145378Z","shell.execute_reply":"2023-06-15T06:10:47.152529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import segmentation_models_pytorch.utils.metrics\nimport segmentation_models_pytorch.utils\n\n# ENCODER = 'resnet50'\nENCODER = 'efficientnet-b1'\nENCODER_WEIGHTS = 'imagenet'\nCLASSES = ['Contrail']\nACTIVATION = 'sigmoid'\n\nmodel = smp.Unet(\n    encoder_name=ENCODER,\n    encoder_weights=None,\n    classes = len(CLASSES),\n    activation = ACTIVATION,\n)\n\n# preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)\n\nTRAINING = True\nEpochs = 30\nloss = smp.utils.losses.DiceLoss()\nmetrics = [smp.utils.metrics.IoU(threshold=0.5)]\noptim = torch.optim.Adam([dict(params=model.parameters(), lr=0.0001)])\n# lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optim, T_0=1, T_mult=2, eta_min=5e-5)\nlr_scheduler = torch.optim.lr_scheduler.OneCycleLR(optim, max_lr=0.001, epochs=Epochs, steps_per_epoch=1284)","metadata":{"execution":{"iopub.status.busy":"2023-06-15T06:10:49.406243Z","iopub.execute_input":"2023-06-15T06:10:49.406608Z","iopub.status.idle":"2023-06-15T06:10:49.815615Z","shell.execute_reply.started":"2023-06-15T06:10:49.406581Z","shell.execute_reply":"2023-06-15T06:10:49.814550Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torchvision.transforms as T\n\ndef false_color(band11, band14, band15):\n    def normalize(band, bounds):\n        return (band - bounds[0]) / (bounds[1] - bounds[0])    \n    _T11_BOUNDS = (243, 303)\n    _CLOUD_TOP_TDIFF_BOUNDS = (-4, 5)\n    _TDIFF_BOUNDS = (-4, 2)\n    r = normalize(band15 - band14, _TDIFF_BOUNDS)\n    g = normalize(band14 - band11, _CLOUD_TOP_TDIFF_BOUNDS)\n    b = normalize(band14, _T11_BOUNDS)\n    return np.clip(np.stack([r, g, b], axis=2), 0, 1)\n\nclass ContrailTestDataset(Dataset):\n    def __init__(self, images_dir, ids, augmentation=None, preprocessing=None):\n        super().__init__()\n        self.image_path = images_dir\n        self.ids = ids\n        \n        self.augmentation = augmentation\n        self.preprocessing = preprocessing\n#         self.normalize_image = T.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n        \n    def __len__(self):\n        return len(self.ids)\n        \n    def __getitem__(self, idx):\n        image_path  = f\"{self.image_path}/{self.ids[idx]}\"\n        band11 = np.load(f\"{image_path}/band_11.npy\")[..., 4]\n        band14 = np.load(f\"{image_path}/band_14.npy\")[..., 4]\n        band15 = np.load(f\"{image_path}/band_15.npy\")[..., 4]\n        image = false_color(band11, band14, band15)\n        \n        if self.augmentation:\n            sample = self.augmentation(image=image)\n            image = sample['image']\n            \n        if self.preprocessing:\n            image = np.transpose(image, (2, 0, 1))\n            \n        image = image.astype(np.float32)\n        image = torch.as_tensor(image)\n#         image = self.normalize_image(image)\n        \n#         image = (image - image.min()) / (image.max() - image.min())\n        # image /= 255.0\n            \n        return image","metadata":{"execution":{"iopub.status.busy":"2023-06-15T06:10:51.361796Z","iopub.execute_input":"2023-06-15T06:10:51.362182Z","iopub.status.idle":"2023-06-15T06:10:51.373244Z","shell.execute_reply.started":"2023-06-15T06:10:51.362152Z","shell.execute_reply":"2023-06-15T06:10:51.372478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = torch.load('/kaggle/input/contrail-model-save2/Resize_384_Epoch130.pth', map_location=DEVICE)","metadata":{"execution":{"iopub.status.busy":"2023-06-15T06:10:56.879373Z","iopub.execute_input":"2023-06-15T06:10:56.879752Z","iopub.status.idle":"2023-06-15T06:10:57.250167Z","shell.execute_reply.started":"2023-06-15T06:10:56.879722Z","shell.execute_reply":"2023-06-15T06:10:57.249360Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ids = os.listdir(test_data_path)\ntest_ds = ContrailTestDataset(test_data_path, ids, get_val_augmentation(), preprocessing=True)\ntest_dl = DataLoader(test_ds, batch_size=1, num_workers=4, shuffle=False, pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2023-06-15T06:12:16.934062Z","iopub.execute_input":"2023-06-15T06:12:16.934522Z","iopub.status.idle":"2023-06-15T06:12:16.946843Z","shell.execute_reply.started":"2023-06-15T06:12:16.934470Z","shell.execute_reply":"2023-06-15T06:12:16.945956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rle_encode(x, fg_val=1):\n    \"\"\"\n    Args:\n        x:  numpy array of shape (height, width), 1 - mask, 0 - background\n    Returns: run length encoding as list\n    \"\"\"\n\n    dots = np.where(\n        x.T.flatten() == fg_val)[0]  # .T sets Fortran order down-then-right\n    run_lengths = []\n    prev = -2\n    for b in dots:\n        if b > prev + 1:\n            run_lengths.extend((b + 1, 0))\n        run_lengths[-1] += 1\n        prev = b\n    return run_lengths\n\n\ndef list_to_string(x):\n    \"\"\"\n    Converts list to a string representation\n    Empty list returns '-'\n    \"\"\"\n    if x: # non-empty list\n        s = str(x).replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\")\n    else:\n        s = '-'\n    return s\n\n\ndef rle_decode(mask_rle, shape=(256, 256)):\n    '''\n    mask_rle: run-length as string formatted (start length)\n              empty predictions need to be encoded with '-'\n    shape: (height, width) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n    '''\n\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    if mask_rle != '-': \n        s = mask_rle.split()\n        starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n        starts -= 1\n        ends = starts + lengths\n        for lo, hi in zip(starts, ends):\n            img[lo:hi] = 1\n    return img.reshape(shape, order='F')  # Needed to align to RLE direction","metadata":{"execution":{"iopub.status.busy":"2023-06-15T06:12:18.329544Z","iopub.execute_input":"2023-06-15T06:12:18.329947Z","iopub.status.idle":"2023-06-15T06:12:18.340432Z","shell.execute_reply.started":"2023-06-15T06:12:18.329916Z","shell.execute_reply":"2023-06-15T06:12:18.339223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def submit_to_csv(test_ids, y_pred):\n    \n    y_encoded = [list_to_string(rle_encode(y)) for y in y_pred]\n    \n    all_test_paths = list(Path('/kaggle/input/google-research-identify-contrails-reduce-global-warming/test').glob(\"*\"))\n    \n    sub_df = pd.DataFrame({'record_id': [path.stem for path in all_test_paths], 'encoded_pixels': y_encoded})\n    \n    print(\"Submitted\")\n    return sub_df","metadata":{"execution":{"iopub.status.busy":"2023-06-15T06:12:20.195314Z","iopub.execute_input":"2023-06-15T06:12:20.195730Z","iopub.status.idle":"2023-06-15T06:12:20.202193Z","shell.execute_reply.started":"2023-06-15T06:12:20.195701Z","shell.execute_reply":"2023-06-15T06:12:20.201101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"out_rle = []\ntest_ids = []\npreds=[]\nmodel.eval()\n\n\nwith torch.inference_mode():\n    for idx, image in enumerate(tqdm(test_dl)):\n        print(\"Test idx:\", idx)\n        image = image.to(DEVICE, dtype=torch.float)\n        \n        pred = model(image)\n        \n        pred = torch.nn.functional.interpolate(pred, size=256, mode='bilinear')\n#         print(pred.shape)\n        \n        pred = (nn.Sigmoid()(pred)>0.5).double()\n    \n        out_reversed = np.array([o.cpu().permute(1,2,0).numpy() for o in pred])\n        for e in out_reversed:\n            out_rle.append(e)","metadata":{"execution":{"iopub.status.busy":"2023-06-15T06:12:21.812505Z","iopub.execute_input":"2023-06-15T06:12:21.813583Z","iopub.status.idle":"2023-06-15T06:12:22.729193Z","shell.execute_reply.started":"2023-06-15T06:12:21.813535Z","shell.execute_reply":"2023-06-15T06:12:22.728040Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_ids = list(os.listdir(\"/kaggle/input/google-research-identify-contrails-reduce-global-warming/test\"))","metadata":{"execution":{"iopub.status.busy":"2023-06-15T06:11:11.268746Z","iopub.execute_input":"2023-06-15T06:11:11.269141Z","iopub.status.idle":"2023-06-15T06:11:11.275526Z","shell.execute_reply.started":"2023-06-15T06:11:11.269108Z","shell.execute_reply":"2023-06-15T06:11:11.274480Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df= submit_to_csv(test_ids, out_rle)","metadata":{"execution":{"iopub.status.busy":"2023-06-15T06:11:13.522912Z","iopub.execute_input":"2023-06-15T06:11:13.523286Z","iopub.status.idle":"2023-06-15T06:11:13.538208Z","shell.execute_reply.started":"2023-06-15T06:11:13.523259Z","shell.execute_reply":"2023-06-15T06:11:13.536577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df","metadata":{"execution":{"iopub.status.busy":"2023-06-15T06:11:15.431085Z","iopub.execute_input":"2023-06-15T06:11:15.431464Z","iopub.status.idle":"2023-06-15T06:11:15.459375Z","shell.execute_reply.started":"2023-06-15T06:11:15.431436Z","shell.execute_reply":"2023-06-15T06:11:15.458302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df.to_csv(\"submission.csv\",index=False)","metadata":{"execution":{"iopub.status.busy":"2023-06-15T06:11:18.124657Z","iopub.execute_input":"2023-06-15T06:11:18.125470Z","iopub.status.idle":"2023-06-15T06:11:18.137925Z","shell.execute_reply.started":"2023-06-15T06:11:18.125437Z","shell.execute_reply":"2023-06-15T06:11:18.137130Z"},"trusted":true},"execution_count":null,"outputs":[]}]}