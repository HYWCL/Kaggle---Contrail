{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":51753,"databundleVersionId":5692552,"sourceType":"competition"},{"sourceId":1323925,"sourceType":"datasetVersion","datasetId":767903},{"sourceId":4125181,"sourceType":"datasetVersion","datasetId":2437947},{"sourceId":5824224,"sourceType":"datasetVersion","datasetId":3347112},{"sourceId":5848162,"sourceType":"datasetVersion","datasetId":3362727},{"sourceId":6109993,"sourceType":"datasetVersion","datasetId":2437951},{"sourceId":6116166,"sourceType":"datasetVersion","datasetId":3454112},{"sourceId":6265862,"sourceType":"datasetVersion","datasetId":3508413,"isSourceIdPinned":false}],"dockerImageVersionId":30498,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Summary\n#### [<u>Initial version</u>](https://www.kaggle.com/code/egortrushin/gr-icrgw-pytorch-lightning-baseline-unet-resnest)\n- Baseline written using Pytorch Lightning\n- resnest26d as encoder\n- Dataset is taken from: https://www.kaggle.com/datasets/shashwatraman/contrails-images-ash-color\n\n#### [<u>Improved version</u>](https://www.kaggle.com/code/egortrushin/gr-icrgw-pl-pipeline-improved)\n- Option to change image size\n- Mixed precision training (only useful with T4x2, on P100 this slows down training). This helps to use GPU memory more efficiently\n- Training using 2 GPUs - with 2 GPUs we have more memory and higher speed\n- Other numerous small changes\n\n#### <u>Present version</u>\n- Training with 4-folds\n- LR scheduler: cosine with warmup\n- Use of CSVLogger with consequent visualization of the optimization process. Since I train without internet, I am limited to *local* CSVLogger or TensorBoardLogger. Alternatively you can train with internet and WanddbLogger.\n- Submission part is rewritten to make it cleaner and to allow easy work with multi-fold models","metadata":{}},{"cell_type":"markdown","source":"### Training part","metadata":{}},{"cell_type":"code","source":"import sys\nsys.path.append(\"../input/pretrained-models-pytorch\")\nsys.path.append(\"../input/efficientnet-pytorch\")\nsys.path.append(\"/kaggle/input/smp-github/segmentation_models.pytorch-master\")\nsys.path.append(\"/kaggle/input/timm-pretrained-resnest/resnest/\")\nimport segmentation_models_pytorch as smp","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-07-28T03:53:37.766369Z","iopub.execute_input":"2023-07-28T03:53:37.766803Z","iopub.status.idle":"2023-07-28T03:53:45.254689Z","shell.execute_reply.started":"2023-07-28T03:53:37.766765Z","shell.execute_reply":"2023-07-28T03:53:45.253712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir -p /root/.cache/torch/hub/checkpoints/\n!cp /kaggle/input/timm-pretrained-resnest/resnest/gluon_resnest26-50eb607c.pth /root/.cache/torch/hub/checkpoints/gluon_resnest26-50eb607c.pth","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-07-28T03:53:47.856141Z","iopub.execute_input":"2023-07-28T03:53:47.856677Z","iopub.status.idle":"2023-07-28T03:53:50.028874Z","shell.execute_reply.started":"2023-07-28T03:53:47.856633Z","shell.execute_reply":"2023-07-28T03:53:50.027493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile config.yaml\n\ndata_path: \"/kaggle/input/contrails-images-ash-color\"\noutput_dir: \"models\"\n\nfolds:\n    n_splits: 4\n    random_state: 42\ntrain_folds: [0]\n    \nseed: 42\n\ntrain_bs: 16\nvalid_bs: 64\nworkers: 2\n\nprogress_bar_refresh_rate: 1\n\nearly_stop:\n    monitor: \"val_loss\"\n    mode: \"min\"\n    patience: 999\n    verbose: 1\n\ntrainer:\n    max_epochs: 20\n    min_epochs: 20\n    enable_progress_bar: True\n    precision: \"16-mixed\"\n    devices: 2\n\nmodel:\n    seg_model: \"Unet\"\n    encoder_name: \"tu-maxvit_rmlp_base_rw_384\" \n    loss_smooth: 1.0\n    image_size: 384\n    optimizer_params:\n        lr: 0.0005\n        weight_decay: 0.0\n    scheduler:\n        name: \"cosine_with_hard_restarts_schedule_with_warmup\"\n        params:\n            cosine_with_hard_restarts_schedule_with_warmup:\n                num_warmup_steps: 350\n                num_training_steps: 3150\n                num_cycles: 1","metadata":{"execution":{"iopub.status.busy":"2023-07-28T03:53:50.035131Z","iopub.execute_input":"2023-07-28T03:53:50.037471Z","iopub.status.idle":"2023-07-28T03:53:50.050492Z","shell.execute_reply.started":"2023-07-28T03:53:50.037427Z","shell.execute_reply":"2023-07-28T03:53:50.049598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Submission part","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport gc\nimport os\nimport glob\n\nimport numpy as np\nimport pandas as pd\n\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\n\nimport pytorch_lightning as pl\nimport torchvision.transforms as T\nimport yaml\n\nwith open(\"config.yaml\", \"r\") as file_obj:\n    config = yaml.safe_load(file_obj)","metadata":{"execution":{"iopub.status.busy":"2023-07-28T03:53:50.055792Z","iopub.execute_input":"2023-07-28T03:53:50.058064Z","iopub.status.idle":"2023-07-28T03:54:03.757049Z","shell.execute_reply.started":"2023-07-28T03:53:50.058012Z","shell.execute_reply":"2023-07-28T03:54:03.756006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 16\nnum_workers = 2\nTHR = 0.4\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndata = '/kaggle/input/google-research-identify-contrails-reduce-global-warming'\ndata_root = '/kaggle/input/google-research-identify-contrails-reduce-global-warming/test/'\nsubmission = pd.read_csv(os.path.join(data, 'sample_submission.csv'), index_col='record_id')","metadata":{"execution":{"iopub.status.busy":"2023-07-28T03:54:03.762075Z","iopub.execute_input":"2023-07-28T03:54:03.764858Z","iopub.status.idle":"2023-07-28T03:54:03.811097Z","shell.execute_reply.started":"2023-07-28T03:54:03.764823Z","shell.execute_reply":"2023-07-28T03:54:03.810189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filenames = os.listdir(data_root)\ntest_df = pd.DataFrame(filenames, columns=['record_id'])\ntest_df['path'] = data_root + test_df['record_id'].astype(str)","metadata":{"execution":{"iopub.status.busy":"2023-07-28T03:54:03.815379Z","iopub.execute_input":"2023-07-28T03:54:03.817678Z","iopub.status.idle":"2023-07-28T03:54:03.830855Z","shell.execute_reply.started":"2023-07-28T03:54:03.817644Z","shell.execute_reply":"2023-07-28T03:54:03.829896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ContrailsDataset(torch.utils.data.Dataset):\n    def __init__(self, df, image_size=256, train=False):\n        \n        self.df = df\n        self.trn = train\n        self.df_idx: pd.DataFrame = pd.DataFrame({'idx': os.listdir(f'/kaggle/input/google-research-identify-contrails-reduce-global-warming/test')})\n        self.normalize_image = T.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n        self.image_size = image_size\n        if image_size != 256:\n            self.resize_image = T.transforms.Resize(image_size)\n        if train:\n            self.hfilp = T.RandomHorizontalFlip(p=1.0)\n    \n    def read_record(self, directory):\n        record_data = {}\n        for x in [\n            \"band_11\", \n            \"band_14\", \n            \"band_15\"\n        ]:\n\n            record_data[x] = np.load(os.path.join(directory, x + \".npy\"))\n\n        return record_data\n\n    def normalize_range(self, data, bounds):\n        \"\"\"Maps data to the range [0, 1].\"\"\"\n        return (data - bounds[0]) / (bounds[1] - bounds[0])\n    \n    def get_false_color(self, record_data):\n        _T11_BOUNDS = (243, 303)\n        _CLOUD_TOP_TDIFF_BOUNDS = (-4, 5)\n        _TDIFF_BOUNDS = (-4, 2)\n        \n        N_TIMES_BEFORE = 4\n\n        r = self.normalize_range(record_data[\"band_15\"] - record_data[\"band_14\"], _TDIFF_BOUNDS)\n        g = self.normalize_range(record_data[\"band_14\"] - record_data[\"band_11\"], _CLOUD_TOP_TDIFF_BOUNDS)\n        b = self.normalize_range(record_data[\"band_14\"], _T11_BOUNDS)\n        false_color = np.clip(np.stack([r, g, b], axis=2), 0, 1)\n        img = false_color[..., N_TIMES_BEFORE]\n\n        return img\n    \n    def __getitem__(self, index):\n        row = self.df.iloc[index]\n        con_path = row.path\n        data = self.read_record(con_path)    \n        \n        img = self.get_false_color(data)\n        \n        img = torch.tensor(np.reshape(img, (256, 256, 3))).to(torch.float32).permute(2, 0, 1)\n        \n        if self.image_size != 256:\n            img = self.resize_image(img)\n            \n        if self.trn:\n            img = self.hflip(img)\n        \n        img = self.normalize_image(img)\n        \n        image_id = int(self.df_idx.iloc[index]['idx'])\n            \n        return img.float(), torch.tensor(image_id)\n    \n    def __len__(self):\n        return len(self.df)","metadata":{"execution":{"iopub.status.busy":"2023-07-28T03:54:03.837397Z","iopub.execute_input":"2023-07-28T03:54:03.839744Z","iopub.status.idle":"2023-07-28T03:54:03.860561Z","shell.execute_reply.started":"2023-07-28T03:54:03.839713Z","shell.execute_reply":"2023-07-28T03:54:03.859330Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rle_encode(x, fg_val=1):\n    \"\"\"\n    Args:\n        x:  numpy array of shape (height, width), 1 - mask, 0 - background\n    Returns: run length encoding as list\n    \"\"\"\n\n    dots = np.where(\n        x.T.flatten() == fg_val)[0]  # .T sets Fortran order down-then-right\n    run_lengths = []\n    prev = -2\n    for b in dots:\n        if b > prev + 1:\n            run_lengths.extend((b + 1, 0))\n        run_lengths[-1] += 1\n        prev = b\n    return run_lengths\n\ndef list_to_string(x):\n    \"\"\"\n    Converts list to a string representation\n    Empty list returns '-'\n    \"\"\"\n    if x: # non-empty list\n        s = str(x).replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\")\n    else:\n        s = '-'\n    return s","metadata":{"execution":{"iopub.status.busy":"2023-07-28T03:54:03.864948Z","iopub.execute_input":"2023-07-28T03:54:03.867677Z","iopub.status.idle":"2023-07-28T03:54:03.879107Z","shell.execute_reply.started":"2023-07-28T03:54:03.867633Z","shell.execute_reply":"2023-07-28T03:54:03.878292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class LightningModule(pl.LightningModule):\n    def __init__(self):\n        super().__init__()\n        self.model = smp.Unet(encoder_name=\"tu-maxvit_rmlp_base_rw_384\",\n                              encoder_weights=None,\n                              in_channels=3,\n                              classes=1,\n                              activation=None,\n                              )\n\n    def forward(self, batch):\n        return self.model(batch)\n    \nclass LightningModule2(pl.LightningModule):\n    def __init__(self):\n        super().__init__()\n        self.model = smp.Unet(encoder_name=\"tu-maxxvitv2_rmlp_base_rw_384\",\n                              encoder_weights=None,\n                              in_channels=3,\n                              classes=1,\n                              activation=None,\n                              )\n\n    def forward(self, batch):\n        return self.model(batch)","metadata":{"execution":{"iopub.status.busy":"2023-07-28T03:54:03.883691Z","iopub.execute_input":"2023-07-28T03:54:03.886298Z","iopub.status.idle":"2023-07-28T03:54:03.897181Z","shell.execute_reply.started":"2023-07-28T03:54:03.886255Z","shell.execute_reply":"2023-07-28T03:54:03.896280Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MODEL_PATH = \"/kaggle/input/contrail-pl-model-save2/tu-maxvit-rmlp-base-rw-HF-384-Epoch30-0/\"\n# MODEL_PATH2 = \"/kaggle/input/contrail-pl-model-save2/tu-maxvit-rmlp-base-rw-384-fold5-Epoch20/\"\n# MODEL_PATH3 = \"/kaggle/input/contrail-pl-model-save2/timm-resnest200e-resnest50d-Ensemble-Fold10\"","metadata":{"execution":{"iopub.status.busy":"2023-07-28T03:54:03.901775Z","iopub.execute_input":"2023-07-28T03:54:03.904454Z","iopub.status.idle":"2023-07-28T03:54:03.912748Z","shell.execute_reply.started":"2023-07-28T03:54:03.904421Z","shell.execute_reply":"2023-07-28T03:54:03.911934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_ds = ContrailsDataset(\n        test_df,\n        config[\"model\"][\"image_size\"],\n        train = False\n    )\n \ntest_dl = DataLoader(test_ds, batch_size=batch_size, num_workers = num_workers)","metadata":{"execution":{"iopub.status.busy":"2023-07-28T03:54:03.917385Z","iopub.execute_input":"2023-07-28T03:54:03.920030Z","iopub.status.idle":"2023-07-28T03:54:03.928585Z","shell.execute_reply.started":"2023-07-28T03:54:03.919999Z","shell.execute_reply":"2023-07-28T03:54:03.927765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm.notebook import tqdm\n\ndef inference_sub(models_paths, device, exp_id, image_size=384, model_number=1):\n    all_preds = {}\n    test_ds = ContrailsDataset(test_df, image_size=384, train=False)\n    test_dl = DataLoader(test_ds, batch_size=batch_size, num_workers=num_workers)\n    \n    predicted_mask = []\n    image_ids = []\n        \n    for fold_no, model_path in enumerate(model_paths):\n        if model_number == 1:\n            model = LightningModule().load_from_checkpoint(model_path, config=\"tu-maxxvit_rmlp_base_rw_384\")\n        elif model_number == 2:\n            model = LightningModule2().load_from_checkpoint(model_path, config=\"tu-maxvitv2_rmlp_base_rw_384\")\n        model.to(device)\n        model.eval()\n        \n        model_preds = {}\n        \n        predicted_mask_all = []\n        \n        for _, data in tqdm(enumerate(test_dl), total=len(test_dl)):\n            images, image_id = data\n            images = images.to(device)\n            \n            with torch.no_grad():\n                predicted_mask = model(images[:, :, :, :])\n                if image_size != 256:\n                    predicted_mask = torch.nn.functional.interpolate(predicted_mask, size=256, mode='bilinear')\n            \n            predicted_mask = torch.sigmoid(predicted_mask).cpu()\n                \n            for img_num in range(0, images.shape[0]):\n                current_mask = predicted_mask[img_num, :, :, :]\n                current_image_id = image_id[img_num].item()\n                model_preds[current_image_id] = current_mask\n                \n        all_preds[f\"{fold_no}\"] = model_preds\n        del model\n        torch.cuda.empty_cache()\n        gc.collect()\n        \n    predictions_list = []\n    \n    for fold_no, model_preds in all_preds.items():\n        predictions = []\n        image_id_list = []\n        for image_id, mask in model_preds.items():\n            predictions.append(mask)\n            image_id_list.append(image_id)\n        predictions_list.append(torch.cat(predictions).reshape(-1, 1, 256, 256))\n    predictions = torch.mean(torch.stack(predictions_list, dim=0), dim=0)\n    np.save(f\"{exp_id}\", predictions.numpy())\n    del all_preds\n    return [], image_id_list","metadata":{"execution":{"iopub.status.busy":"2023-07-28T03:54:03.932820Z","iopub.execute_input":"2023-07-28T03:54:03.934437Z","iopub.status.idle":"2023-07-28T03:54:03.954491Z","shell.execute_reply.started":"2023-07-28T03:54:03.934404Z","shell.execute_reply":"2023-07-28T03:54:03.953382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model_paths = [\n#     '/kaggle/input/contrail-pl-model-save2/tu-maxxvitv2_rmlp_base_rw_384-fold5-Epoch20/v2-model-f0-val_dice=0.6798.ckpt',\n#     '/kaggle/input/contrail-pl-model-save2/tu-maxxvitv2_rmlp_base_rw_384-fold5-Epoch20/v2-model-f1-val_dice=0.6776.ckpt',\n#     '/kaggle/input/contrail-pl-model-save2/tu-maxxvitv2_rmlp_base_rw_384-fold5-Epoch20/v2-model-f2-val_dice=0.6754.ckpt',\n#     '/kaggle/input/contrail-pl-model-save2/tu-maxxvitv2_rmlp_base_rw_384-fold5-Epoch20/v2-model-f3-val_dice=0.6813.ckpt',\n#     '/kaggle/input/contrail-pl-model-save2/tu-maxxvitv2_rmlp_base_rw_384-fold5-Epoch20/v2-model-f4-val_dice=0.6793.ckpt'\n# ]\n\nmodel_paths = [\n    '/kaggle/input/contrail-pl-model-save2/tu-maxvit-rmlp-base-rw-384-fold5-Epoch20/model-f0-val_dice=0.6800.ckpt',\n    '/kaggle/input/contrail-pl-model-save2/tu-maxvit-rmlp-base-rw-384-fold5-Epoch20/model-f1-val_dice=0.6777.ckpt',\n    '/kaggle/input/contrail-pl-model-save2/tu-maxvit-rmlp-base-rw-384-fold5-Epoch20/model-f2-val_dice=0.6741.ckpt',\n    '/kaggle/input/contrail-pl-model-save2/tu-maxvit-rmlp-base-rw-384-fold5-Epoch20/model-f3-val_dice=0.6810.ckpt',\n    '/kaggle/input/contrail-pl-model-save2/tu-maxvit-rmlp-base-rw-384-fold5-Epoch20/model-f4-val_dice=0.6786.ckpt'\n]\n\nexp1_384_preds, image_ids = inference_sub(model_paths, device, '1', image_size=384, model_number=1)\n\nmodel_paths = [\n    '/kaggle/input/contrail-pl-model-save2/tu-maxvit-rmlp-base-rw-384-fold5-Epoch20-Frame6/model-f0-val_dice=0.6876.ckpt',\n    '/kaggle/input/contrail-pl-model-save2/tu-maxvit-rmlp-base-rw-384-fold5-Epoch20-Frame6/model-f1-val_dice=0.6863.ckpt',\n    '/kaggle/input/contrail-pl-model-save2/tu-maxvit-rmlp-base-rw-384-fold5-Epoch20-Frame6/model-f2-val_dice=0.6846.ckpt',\n    '/kaggle/input/contrail-pl-model-save2/tu-maxvit-rmlp-base-rw-384-fold5-Epoch20-Frame6/model-f3-val_dice=0.6839.ckpt',\n    '/kaggle/input/contrail-pl-model-save2/tu-maxvit-rmlp-base-rw-384-fold5-Epoch20-Frame6/model-f4-val_dice=0.6887.ckpt'\n]\n\nexp2_384_preds, image_ids = inference_sub(model_paths, device, '2', image_size=384, model_number=1)","metadata":{"execution":{"iopub.status.busy":"2023-07-28T03:55:29.779694Z","iopub.execute_input":"2023-07-28T03:55:29.780056Z","iopub.status.idle":"2023-07-28T03:58:18.866050Z","shell.execute_reply.started":"2023-07-28T03:55:29.780028Z","shell.execute_reply":"2023-07-28T03:58:18.864991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv(os.path.join(data, 'sample_submission.csv'))","metadata":{"execution":{"iopub.status.busy":"2023-07-28T03:59:32.850886Z","iopub.execute_input":"2023-07-28T03:59:32.851308Z","iopub.status.idle":"2023-07-28T03:59:32.864731Z","shell.execute_reply.started":"2023-07-28T03:59:32.851269Z","shell.execute_reply":"2023-07-28T03:59:32.863781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import math\n\nexp1_preds = np.load('1.npy', mmap_mode='r')\nexp2_preds = np.load('2.npy', mmap_mode='r')\n\npreds_final = []\n\nCHUNK_SIZE = 150\nCHUNKS = math.ceil(len(test_df) / CHUNK_SIZE)\nstart_idx = 0\n\nfor i in range(CHUNKS):\n    preds_final.append(\n        (exp1_preds[start_idx:start_idx + CHUNK_SIZE])*.7  + (exp2_preds[start_idx:start_idx + CHUNK_SIZE])*.3\n    )\n    start_idx += CHUNK_SIZE\n    \npreds_final = np.concatenate(preds_final)\npredicted_mask = preds_final\n\nfor idx, (image_id, mask) in enumerate(zip(image_ids, predicted_mask)):\n    predicted_mask_with_threshold = np.zeros((256, 256))\n    predicted_mask_with_threshold[mask[0, :, :] < .4] = 0\n    predicted_mask_with_threshold[mask[0, :, :] > .4] = 1\n    \n    submission.loc[submission['record_id'] == image_id, 'encoded_pixels'] = list_to_string(rle_encode(predicted_mask_with_threshold))","metadata":{"execution":{"iopub.status.busy":"2023-07-28T04:01:12.752740Z","iopub.execute_input":"2023-07-28T04:01:12.753094Z","iopub.status.idle":"2023-07-28T04:01:13.620817Z","shell.execute_reply.started":"2023-07-28T04:01:12.753066Z","shell.execute_reply":"2023-07-28T04:01:13.618475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = submission.set_index('record_id')","metadata":{"execution":{"iopub.status.busy":"2023-07-28T03:59:41.267355Z","iopub.execute_input":"2023-07-28T03:59:41.267702Z","iopub.status.idle":"2023-07-28T03:59:41.276859Z","shell.execute_reply.started":"2023-07-28T03:59:41.267674Z","shell.execute_reply":"2023-07-28T03:59:41.275794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os, glob\nfor filename in glob.glob(\"/kaggle/working/*.npy\"):\n    os.remove(filename) ","metadata":{"execution":{"iopub.status.busy":"2023-07-28T03:59:42.851303Z","iopub.execute_input":"2023-07-28T03:59:42.851652Z","iopub.status.idle":"2023-07-28T03:59:42.857498Z","shell.execute_reply.started":"2023-07-28T03:59:42.851625Z","shell.execute_reply":"2023-07-28T03:59:42.856487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission.csv')","metadata":{"execution":{"iopub.status.busy":"2023-07-28T03:59:44.756297Z","iopub.execute_input":"2023-07-28T03:59:44.756649Z","iopub.status.idle":"2023-07-28T03:59:44.767673Z","shell.execute_reply.started":"2023-07-28T03:59:44.756620Z","shell.execute_reply":"2023-07-28T03:59:44.766700Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.head()","metadata":{"execution":{"iopub.status.busy":"2023-07-28T03:59:46.249886Z","iopub.execute_input":"2023-07-28T03:59:46.250275Z","iopub.status.idle":"2023-07-28T03:59:46.265815Z","shell.execute_reply.started":"2023-07-28T03:59:46.250222Z","shell.execute_reply":"2023-07-28T03:59:46.264753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# gc.enable()\n\n# all_preds = {}\n\n# model_paths_combined = glob.glob(MODEL_PATH + '*.ckpt') # + glob.glob(MODEL_PATH2 + '*.ckpt') # + glob.glob(MODEL_PATH3 + '*.ckpt')\n\n# for i, model_path in enumerate(model_paths_combined):\n#     print(model_path)\n    \n#     if model_path.find(\"v2-model\") != -1:\n#         model = LightningModule2().load_from_checkpoint(model_path, config=\"tu-maxxvitv2_rmlp_base_rw_384\")\n#     else:\n#         model = LightningModule().load_from_checkpoint(model_path, config=\"tu-maxxvit_rmlp_base_rw_384\")\n        \n#     model.to(device)\n#     model.eval()\n\n#     model_preds = {}\n    \n#     for _, data in enumerate(test_dl):\n#         images, image_id = data\n    \n#         images = images.to(device)\n        \n#         with torch.no_grad():\n#             predicted_mask = model(images[:, :, :, :])\n#         if config[\"model\"][\"image_size\"] != 256:\n#             predicted_mask = torch.nn.functional.interpolate(predicted_mask, size=256, mode='bilinear')\n#         predicted_mask = torch.sigmoid(predicted_mask).cpu().detach().numpy()\n                \n#         for img_num in range(0, images.shape[0]):\n#             current_mask = predicted_mask[img_num, :, :, :]\n#             current_image_id = image_id[img_num].item()\n#             model_preds[current_image_id] = current_mask\n#     all_preds[f\"f{i}\"] = model_preds\n    \n#     del model    \n#     torch.cuda.empty_cache()\n#     gc.collect() ","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-07-28T04:06:36.351709Z","iopub.execute_input":"2023-07-28T04:06:36.352178Z","iopub.status.idle":"2023-07-28T04:07:37.781267Z","shell.execute_reply.started":"2023-07-28T04:06:36.352134Z","shell.execute_reply":"2023-07-28T04:07:37.778847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for index in submission.index.tolist():\n#     for i in range(len(glob.glob(MODEL_PATH + '*.ckpt'))):\n#         if i == 0:\n#             predicted_mask = all_preds[f\"f{i}\"][index]\n#         else:\n#             predicted_mask += all_preds[f\"f{i}\"][index]\n#     predicted_mask = predicted_mask / len(glob.glob(MODEL_PATH + '*.ckpt'))\n#     predicted_mask_with_threshold = np.zeros((256, 256))\n#     predicted_mask_with_threshold[predicted_mask[0, :, :] < THR] = 0\n#     predicted_mask_with_threshold[predicted_mask[0, :, :] > THR] = 1\n#     submission.loc[int(index), 'encoded_pixels'] = list_to_string(rle_encode(predicted_mask_with_threshold))","metadata":{"execution":{"iopub.status.busy":"2023-07-02T14:08:08.653657Z","iopub.execute_input":"2023-07-02T14:08:08.654387Z","iopub.status.idle":"2023-07-02T14:08:08.674353Z","shell.execute_reply.started":"2023-07-02T14:08:08.654350Z","shell.execute_reply":"2023-07-02T14:08:08.673109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submission","metadata":{"execution":{"iopub.status.busy":"2023-07-02T14:08:08.676446Z","iopub.execute_input":"2023-07-02T14:08:08.676958Z","iopub.status.idle":"2023-07-02T14:08:08.699134Z","shell.execute_reply.started":"2023-07-02T14:08:08.676912Z","shell.execute_reply":"2023-07-02T14:08:08.697845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submission.to_csv('submission.csv')","metadata":{"execution":{"iopub.status.busy":"2023-07-02T14:08:08.701004Z","iopub.execute_input":"2023-07-02T14:08:08.701421Z","iopub.status.idle":"2023-07-02T14:08:08.711056Z","shell.execute_reply.started":"2023-07-02T14:08:08.701384Z","shell.execute_reply":"2023-07-02T14:08:08.709755Z"},"trusted":true},"execution_count":null,"outputs":[]}]}